{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fcd81c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\RGBD_Fusion\\.venv\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "f:\\RGBD_Fusion\\.venv\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "f:\\RGBD_Fusion\\.venv\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "f:\\RGBD_Fusion\\.venv\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Eval RGB-only: 100%|██████████| 66/66 [00:03<00:00, 17.23it/s]\n",
      "Eval Early: 100%|██████████| 66/66 [00:04<00:00, 13.33it/s]\n",
      "Eval Mid: 100%|██████████| 66/66 [00:05<00:00, 12.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Model    |   Accuracy(%) |   Precision(%) |   Recall(%) |   F1(%) |   Lat(ms/img) |   FPS |   VRAM(GB) |   Params(M) |   FLOPs(G) |\n",
      "|:---------|--------------:|---------------:|------------:|--------:|--------------:|------:|-----------:|------------:|-----------:|\n",
      "| RGB-only |          97.3 |           97.3 |        97.4 |    97.3 |          12.2 |  81.8 |       3.94 |        41.1 |      177.6 |\n",
      "| Early    |          97.9 |           97.9 |        98   |    97.9 |          11.5 |  86.6 |       3.95 |        41.1 |      178.3 |\n",
      "| Mid      |          97.9 |           98   |        98   |    97.9 |          15.7 |  63.6 |       5.21 |        65.9 |      245.5 |\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from ptflops import get_model_complexity_info\n",
    "from tqdm import tqdm\n",
    "\n",
    "# your training scripts must be importable:\n",
    "from train_rgb_only_fasterrcnn import get_fasterrcnn_rgb, RGBDataset, collate_fn as collate_rgb\n",
    "from train_4ch_fasterrcnn_with_accuracy import get_fasterrcnn_4ch, EarlyFusionDataset, collate_fn as collate_early\n",
    "from midfusion_train_complete_fixed import build_midfusion_fasterrcnn, RGBDDetectionDataset, collate_fn as collate_mid\n",
    "\n",
    "# ─── CONFIG ────────────────────────────────────────────────────────────────────\n",
    "DEVICE     = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "ROOT_DIR   = \"Processed_data\"\n",
    "WEIGHTS_RGB   = \"rgb_only_best.pth\"\n",
    "WEIGHTS_EARLY = \"best_fasterrcnn_4ch1.pth\"\n",
    "WEIGHTS_MID   = \"midfusion_best1.pth\"\n",
    "BATCH_SIZE = 4\n",
    "VAL_SPLIT  = 0.2\n",
    "SEED       = 42\n",
    "\n",
    "# map labels 1→bottle … 6→stapler\n",
    "LABEL_MAP = {\n",
    "    1: \"bottle\", 2: \"glass\", 3: \"marker\",\n",
    "    4: \"mobile\", 5: \"mouse\",  6: \"stapler\"\n",
    "}\n",
    "# ───────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "def compute_iou(a, b):\n",
    "    xA = max(a[0], b[0]); yA = max(a[1], b[1])\n",
    "    xB = min(a[2], b[2]); yB = min(a[3], b[3])\n",
    "    inter = max(0, xB-xA) * max(0, yB-yA)\n",
    "    areaA = (a[2]-a[0])*(a[3]-a[1])\n",
    "    areaB = (b[2]-b[0])*(b[3]-b[1])\n",
    "    uni = areaA + areaB - inter\n",
    "    return inter/uni if uni>0 else 0.0\n",
    "\n",
    "def make_val_loader(ds_cls, collate_fn):\n",
    "    ds = ds_cls(ROOT_DIR)\n",
    "    n_val = int(len(ds)*VAL_SPLIT)\n",
    "    _, vds = random_split(ds, [len(ds)-n_val, n_val],\n",
    "                          generator=torch.Generator().manual_seed(SEED))\n",
    "    return DataLoader(vds, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                      num_workers=0, collate_fn=collate_fn)\n",
    "\n",
    "loaders = {\n",
    "    \"RGB-only\": make_val_loader(RGBDataset, collate_rgb),\n",
    "    \"Early\":    make_val_loader(EarlyFusionDataset, collate_early),\n",
    "    \"Mid\":      make_val_loader(RGBDDetectionDataset, collate_mid),\n",
    "}\n",
    "\n",
    "# build & load models\n",
    "models = {}\n",
    "# RGB-only\n",
    "m_rgb = get_fasterrcnn_rgb(num_classes=len(LABEL_MAP)+1)\n",
    "m_rgb.load_state_dict(torch.load(WEIGHTS_RGB, map_location=DEVICE))\n",
    "models[\"RGB-only\"] = m_rgb.to(DEVICE).eval()\n",
    "\n",
    "# Early-fusion\n",
    "m_early = get_fasterrcnn_4ch(num_classes=len(LABEL_MAP)+1,\n",
    "                             weights_path=WEIGHTS_EARLY,\n",
    "                             device=DEVICE)\n",
    "models[\"Early\"] = m_early.eval()\n",
    "\n",
    "# Mid-fusion\n",
    "m_mid = build_midfusion_fasterrcnn(num_classes=len(LABEL_MAP)+1)\n",
    "m_mid.load_state_dict(torch.load(WEIGHTS_MID, map_location=DEVICE))\n",
    "models[\"Mid\"] = m_mid.to(DEVICE).eval()\n",
    "\n",
    "rows = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    loader = loaders[name]\n",
    "    torch.cuda.reset_peak_memory_stats() if DEVICE.type==\"cuda\" else None\n",
    "\n",
    "    gt_all, pred_all = [], []\n",
    "    latencies = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc=f\"Eval {name}\"):\n",
    "            # unpack\n",
    "            if name == \"Mid\":\n",
    "                rgbs, depths, tgts = batch\n",
    "                inputs = [torch.cat([r,d],0).to(DEVICE)\n",
    "                          for r,d in zip(rgbs, depths)]\n",
    "                targets = tgts\n",
    "            else:\n",
    "                imgs, tgts = batch\n",
    "                inputs = [img.to(DEVICE) for img in imgs]\n",
    "                targets = tgts\n",
    "\n",
    "            t0 = time.time()\n",
    "            outs = model(inputs)\n",
    "            if DEVICE.type==\"cuda\": torch.cuda.synchronize()\n",
    "            latencies.append(time.time()-t0)\n",
    "\n",
    "            # match each GT box to best pred\n",
    "            for out, tgt in zip(outs, targets):\n",
    "                gt_boxes  = tgt[\"boxes\"].cpu().numpy()\n",
    "                gt_labels = tgt[\"labels\"].cpu().numpy()\n",
    "                pb  = out[\"boxes\"].cpu().numpy()\n",
    "                pl  = out[\"labels\"].cpu().numpy()\n",
    "                ps  = out[\"scores\"].cpu().numpy()\n",
    "                keep = ps >= 0.5\n",
    "                pb, pl = pb[keep], pl[keep]\n",
    "                if len(gt_boxes)==0 or len(pb)==0: continue\n",
    "\n",
    "                for gb, gl in zip(gt_boxes, gt_labels):\n",
    "                    ious = [compute_iou(gb, p) for p in pb]\n",
    "                    j = int(np.argmax(ious))\n",
    "                    if ious[j] >= 0.5:\n",
    "                        gt_all.append(int(gl))\n",
    "                        pred_all.append(int(pl[j]))\n",
    "\n",
    "    # compute metrics\n",
    "    acc = sum(1 for g,p in zip(gt_all, pred_all) if g==p) / len(gt_all)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(\n",
    "        gt_all, pred_all, average=\"macro\", zero_division=0\n",
    "    )\n",
    "    cm = confusion_matrix(gt_all, pred_all,\n",
    "                          labels=list(LABEL_MAP.keys()))\n",
    "\n",
    "    # timing & memory\n",
    "    avg_batch = np.mean(latencies)\n",
    "    avg_img_ms = avg_batch / BATCH_SIZE * 1000\n",
    "    fps = 1 / (avg_img_ms/1000)\n",
    "    peak_vram = (torch.cuda.max_memory_allocated()/1e9\n",
    "                 if DEVICE.type==\"cuda\" else np.nan)\n",
    "\n",
    "    # complexity\n",
    "    shape = (3,480,640) if name==\"RGB-only\" else (4,480,640)\n",
    "    macs, params = get_model_complexity_info(\n",
    "        model, shape, as_strings=False, print_per_layer_stat=False\n",
    "    )\n",
    "\n",
    "    rows.append({\n",
    "        \"Model\":        name,\n",
    "        \"Accuracy(%)\":  f\"{acc*100:.1f}\",\n",
    "        \"Precision(%)\": f\"{prec*100:.1f}\",\n",
    "        \"Recall(%)\":    f\"{rec*100:.1f}\",\n",
    "        \"F1(%)\":        f\"{f1*100:.1f}\",\n",
    "        \"Lat(ms/img)\":  f\"{avg_img_ms:.1f}\",\n",
    "        \"FPS\":          f\"{fps:.1f}\",\n",
    "        \"VRAM(GB)\":     f\"{peak_vram:.2f}\",\n",
    "        \"Params(M)\":    f\"{params/1e6:.1f}\",\n",
    "        \"FLOPs(G)\":     f\"{macs/1e9:.1f}\"\n",
    "    })\n",
    "\n",
    "# show Markdown table\n",
    "df = pd.DataFrame(rows)\n",
    "print(df.to_markdown(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f32f69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
